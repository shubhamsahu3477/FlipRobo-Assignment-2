{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FR - Web Scraping - Assignment - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's import all the required libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's load the drivers and URL\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's call the Function Definition\n",
    "\n",
    "#Let's enter the details in the search column\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#Let's enter the job title and location \n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's create empty list for storing the data\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MIS/ Data Analyst-(SQL,Automation,Excel/PowerBI,Dashboards) - Contract',\n",
       " 'Data Analyst - SAP',\n",
       " 'Hiring Data Analysts on Contract',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Security Data Analyst',\n",
       " 'Data Analyst -Azure Data lake, Azure Data factory',\n",
       " 'Business / Data Analyst',\n",
       " 'Data Analyst - O2C - Bangalore',\n",
       " 'Intern Data Analyst',\n",
       " 'NiFi Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Requirement For Data Analyst(Advance excel candidates)',\n",
       " 'SENIOR DATA ANALYST',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Looking For Rockstar Data Analyst @ Freshtohome (Series-C funded Comp)',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job tile\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru',\n",
       " 'Pune, Delhi, Bengaluru, Gurgaon',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Chennai, Pune, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Chennai, Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Chennai, Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru(2nd Phase JP Nagar)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job location\n",
    "\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flipkart Internet Private Limited',\n",
       " 'Boston Scientific Corporation',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Schneider Electric',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'Philips India Limited',\n",
       " 'Mindtree Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Outsource Big Data',\n",
       " 'Capgemini Technology Services India Limited',\n",
       " 'Reliance Jio Infocomm Ltd.',\n",
       " 'Emagine People Technologies Private Limited',\n",
       " 'McAfee Software (India) Pvt. Ltd',\n",
       " 'EZEU',\n",
       " 'Career Hotspot & Services',\n",
       " 'NetApp',\n",
       " 'AceNet',\n",
       " 'Freshtohome Foods Private Limited',\n",
       " 'Liventus, Inc.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the company name\n",
    "\n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-4 Yrs',\n",
       " '4,50,000 - 5,50,000 PA.',\n",
       " 'Bengaluru',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Pune, Delhi, Bengaluru, Gurgaon',\n",
       " '2-5 Yrs',\n",
       " '3,00,000 - 6,00,000 PA.',\n",
       " 'Bengaluru',\n",
       " '2-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru / Bangalore',\n",
       " '5-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '2-4 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '5-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Chennai, Pune, Bengaluru, Hyderabad',\n",
       " '2-4 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '2-4 Yrs',\n",
       " '3,25,000 - 4,50,000 PA.',\n",
       " 'Bengaluru',\n",
       " '0-1 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '4-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '8-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '0-2 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Chennai, Bengaluru',\n",
       " '7-12 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '2-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '2-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '6-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Chennai, Bengaluru',\n",
       " '2-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bengaluru',\n",
       " '3-6 Yrs',\n",
       " '6,00,000 - 10,00,000 PA.',\n",
       " 'Bengaluru(2nd Phase JP Nagar)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the exoerience required\n",
    "\n",
    "experience=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')\n",
    "for i in experience:\n",
    "    experience_required.append(i.text)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - SAP</td>\n",
       "      <td>Pune, Delhi, Bengaluru, Gurgaon</td>\n",
       "      <td>Boston Scientific Corporation</td>\n",
       "      <td>4,50,000 - 5,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Security Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Pune, Delhi, Bengaluru, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst -Azure Data lake, Azure Data factory</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business / Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3,00,000 - 6,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Intern Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Outsource Big Data</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...   \n",
       "1                                 Data Analyst - SAP   \n",
       "2                   Hiring Data Analysts on Contract   \n",
       "3                                Senior Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                              Security Data Analyst   \n",
       "6  Data Analyst -Azure Data lake, Azure Data factory   \n",
       "7                            Business / Data Analyst   \n",
       "8                     Data Analyst - O2C - Bangalore   \n",
       "9                                Intern Data Analyst   \n",
       "\n",
       "                          Job Location                         Company Name  \\\n",
       "0                            Bengaluru    Flipkart Internet Private Limited   \n",
       "1      Pune, Delhi, Bengaluru, Gurgaon        Boston Scientific Corporation   \n",
       "2                            Bengaluru    Flipkart Internet Private Limited   \n",
       "3                Bengaluru / Bangalore                   Schneider Electric   \n",
       "4                            Bengaluru  Shell India Markets Private Limited   \n",
       "5                            Bengaluru                Philips India Limited   \n",
       "6  Chennai, Pune, Bengaluru, Hyderabad                     Mindtree Limited   \n",
       "7                            Bengaluru               IBM India Pvt. Limited   \n",
       "8                            Bengaluru               RANDSTAD INDIA PVT LTD   \n",
       "9                            Bengaluru                   Outsource Big Data   \n",
       "\n",
       "               Experience Required  \n",
       "0                          1-4 Yrs  \n",
       "1          4,50,000 - 5,50,000 PA.  \n",
       "2                        Bengaluru  \n",
       "3                          3-5 Yrs  \n",
       "4                    Not disclosed  \n",
       "5  Pune, Delhi, Bengaluru, Gurgaon  \n",
       "6                          2-5 Yrs  \n",
       "7          3,00,000 - 6,00,000 PA.  \n",
       "8                        Bengaluru  \n",
       "9                          2-5 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "\n",
    "data_analyst_jobs=pd.DataFrame({})\n",
    "data_analyst_jobs['Job Title']=job_title[0:10]    \n",
    "data_analyst_jobs['Job Location']=job_location[0:10]\n",
    "data_analyst_jobs['Company Name']=company_name[0:10]\n",
    "data_analyst_jobs['Experience Required']=experience_required[0:10]\n",
    "data_analyst_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's load the drivers and URL\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's call the Function Definition\n",
    "\n",
    "#Let's navigate to search column\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#Let's enter the job title and location\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's create empty list for storing the data\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Python/ MATLAB/ Machine Learning Algorithms',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Data Scientist - Machine Learning (Commerce BU)',\n",
       " 'Data Scientist',\n",
       " 'Opening For Sr. Data Scientist @ Tech Mahindra',\n",
       " 'Opening For Sr. Data Scientist @ Tech Mahindra',\n",
       " 'Senior Data Scientist - NLP/ Python/ R',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Data Scientist and Senior Data Scientist Academic Operations',\n",
       " 'Sr. Analyst-Data Scientist',\n",
       " 'Sr . Data Scientist',\n",
       " 'DATA SCIENTIST / MACHINE LEARNING EXPERT',\n",
       " 'Artificial Intelligence Analyst/Data Scientist',\n",
       " 'Tech Mahindra is hiring For Data Scientist- Bangalore',\n",
       " 'Data Scientist - Advanced Analytics',\n",
       " 'Senior Data Scientist - Growth Markets',\n",
       " 'Data Scientist',\n",
       " 'Jr. Analyst- Data Scientist',\n",
       " 'Data Scientist/Data Analyst-immediate',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job tile\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Chennai, Pune, Mumbai, Bengaluru',\n",
       " 'Pune, Bengaluru',\n",
       " 'Pune, Bengaluru',\n",
       " 'Bengaluru, Hyderabad',\n",
       " 'Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, Hyderabad, Kolkata',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Mumbai, Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Chennai, Pune, Bengaluru, Hyderabad',\n",
       " 'Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Bengaluru, Gurgaon, Agra, Bharuch, Jaunpur, Nagpur, Delhi, Mumbai, Jaipur, Jhansi']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job location\n",
    "\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wrackle Technologies Pvt Ltd',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'BLUE YONDER INDIA PRIVATE LIMITED',\n",
       " 'Atos Syntel Private Limited',\n",
       " 'Tech Mahindra Ltd.',\n",
       " 'Tech Mahindra Ltd.',\n",
       " 'AVI Consulting LLP',\n",
       " 'CES Ltd.',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Mindtree Limited',\n",
       " 'NetApp',\n",
       " 'Spectrus',\n",
       " 'TalentCo Search Pvt Ltd',\n",
       " 'tech mahindra ltd',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Twitter',\n",
       " 'Diverse Lynx',\n",
       " 'Mindtree Limited',\n",
       " 'CAIA-Center For Artificial Intelligence & Advanced Analytics',\n",
       " 'Country Veggie']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the company name\n",
    "\n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description\\nData Scientist - Data Mining/ Machine Learning/ Statistical Analysis\\n\\nRequirements :\\n\\n- 3-9 years of strong experience in data mining, machine learning, and statistical analysis.\\n\\n- BS/MS/Ph.D. in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Matlab, Python, etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.\\nRoleDatabase Architect/Designer\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Sc in Computers, Statistics, Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization, MS/M.Sc(Science) in Computers, Statistics\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData ScienceData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " 'Job description\\nRoles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.\\nRoleData Analyst\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Other Specialization, Computers, Statistics\\nPG :MS/M.Sc(Science) in Computers, Statistics\\nDoctorate :Ph.D in Statistics, Computers, Other Doctorate\\nKey Skills\\nData ScienceRData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " 'Not Available',\n",
       " 'Job description\\nWorking experience in Artificial Intelligence, Python, R, Machine Learning\\nExperience in data mining, Strong math skills (e.g. statistics, algebra)\\nStrong programming skills in: R, Python and familiarity with Java, Scala, C - DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift\\nExperience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20\\nStrong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc)\\nExperience with Deep Learning tools Tensorflow, Theano, Caffe etc. - Elastic Search, NLP background and Machine Learning Platforms\\nExperienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)\\nExperience in neural networks, regression, classification and clustering\\nDeep industry knowledge on any of the following: Banking, Insurance, Retail Manufacturing\\nDeep understanding of Statistical algorithms: Linear and Non-Linear models, classification problem, optimization techniques, Market mix models, A/B Testing and campaign management, Feature ranking/selection techniques, supervised/unsupervised learning, Collaborative filtering, Apriori Market Basket analysis, SVM, Gradient boosting, Survival analysis etc.\\nTo help designing, innovating and building our next generation ML architecture\\nFull time programming experience within an operation or technical department.\\nIdentify valuable data sources and automate collection processes\\nUndertake pre-processing of structured and unstructured data\\nAnalyze large amounts of information to discover trends and patterns\\nBuild predictive models and machine-learning algorithms\\nCombine models through ensemble modelling\\nPresent information using data visualization techniques\\nPropose solutions and strategies to business challenges\\nCollaborate with engineering and product development teams\\nMentor others in the use of AI/Machine Learning\\nRoleSubject Matter Expert\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategorySystem Design/Implementation/ERP/CRM\\nEducation\\nUG :Any Graduate in Any Specialization, Graduation Not Required\\nPG :Post Graduation Not Required, Any Postgraduate in Any Specialization\\nDoctorate :Doctorate Not Required, Any Doctorate in Any Specialization\\nKey Skills\\nR AnalyticsArtificial IntelligenceData ScientistMachine LearningPython',\n",
       " 'Not Available',\n",
       " 'Not Available',\n",
       " 'Job description\\nRoles and Responsibilities\\nSkill : NLP,Semantic model, NER model, Deep Learning\\n\\nNotice : who can join in a month max\\n\\nJob description :\\n\\n- 5+ years of experience using analytical toolslanguages like Python & R on large scale data\\n\\n- Must have Semantic model & NER experience\\n\\n- Experience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\\n\\n- Experience on Deep Learning for Image processing, Video analytics will be a plus\\n\\n- Must have strong experience in NLPNLGNLU applications using any popular Deep learning frameworks like Open CV, PyTorch, Theano, Tensor Flow, Caffe. Should have implemented solutions for industry use cases.\\n\\n- Demonstrated ability to engage with client stakeholders at multiple levels and provide consultative solutioning across different domains\\n\\n- Deep knowledge of techniques such as Linear Regression, gradient descent, Logistic Regression, Forecasting, Cluster analysis, Decision trees, Linear Optimization, Text Mining etc.\\n\\n- Must have experience in doing POCs\\n\\n- Strong applied fundamentals in data management, parallel computing and distributed systems; experience in productionizing & retraining models\\n\\n- Ability to guide and mentor teams of associates on solution development and approaches\\n\\n- Broad knowledge of fundamentals and state-of-the-art in NLP and machine learning\\n\\n- Coding skills in one or more programming languages such as Python, Scala, Java, C, C++\\n\\n- Expert high level of understanding on language semantic concepts & data standardization\\n\\n- Proven track record of successful models and practical implementation\\n\\n- Hands-on experience with popular ML frameworks such as TensorFlow\\n\\n- Experience with application development practices at scale, from problem definition to deployment.\\n\\n- Familiarity with Cloud services such as AWS, SageMaker etc. is considered a plus\\n\\n- Develop and apply Statistical Modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications\\n\\n- Knowledge in Machine Learning techniques in entity resolution, common speech products or text search domain\\nRoleData Analyst\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Any Specialization, B.Tech/B.E. in Any Specialization, BCA in Computers\\nPG :Any Postgraduate in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nTensorflowRNLPVideo AnalyticsData ScientistImage ProcessingData ModelingNLU/NLGDeep LearningPython',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\nMust have strong Python Programming Skills\\nStrong analytical & algorithm development skills\\nLogical and Analytical skills must be really strong\\nMust have worked in DeepLearning Efforts - Especially computer vision.\\nMust have experinece with Object Detection - Custom model training for Object detection\\nShould have experience with atleast one or more of these - Tensorflow, Keras, PyTorch\\n\\nPrimary Skills - Python + tensorflow - Keras / PyTorch, OpenCV\\nPerks and Benefits\\n\\nKindly share your resume to kandavelkumar.lakshmanan @cesltd.com\\n\\nRoleTechnical Architect\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nTensorflowObject DetectionAlgorithm DevelopmentAnalytical SkillsProgrammingMachine LearningDeep LearningPytorchData ScienceROpencvKerasComputer VisionPython',\n",
       " \"Job description\\n\\nWe are hiring Data Scientist and Senior Data Scientist Academic Operations for our leading EdTech Client.\\n\\nCall/WhatsApp- Amit-9379292728\\nEmail: amitkumar.s@randstad.in\\n\\nor Fill the google form - https://tinyurl.com/JobAppForm4\\n\\nJob Responsibilities:\\nYour primary job responsibility will include (and not limited to):\\nOwn the student's learning outcomes by providing them with support on the topics covered in the\\ncurriculum.\\nInvolve in the residency class room sessions to facilitate lectures and lab sessions\\nBe the first point contact for participants for academic queries and manage discussion\\ngroups\\nMonitor participants academic performance and make learning interventions in the\\nform of remedial sessions, coaching and mentoring\\n\\nCoordinate with faculty to create best in class learning material - video, reading material,\\nassignments, exams\\nDesign and conduct examinations to measure the learning outcome of participants\\nIdentify & Solve interesting problems involving rich datasets in various domains.\\nAccordingly, create capstone projects on the evolving use cases in the industry\\nIdentify key emerging trends in the industry and maintain a rich reference material\\nAssist program director and senior operations and academics managers in planning\\non-campus sessions, preparing schedules, evaluation and grading\\nIdentify key reporting metric sand create dashboards to enable quick decision making\\nAutomation of manual data collection, data cleansing and exploratory data analysis\\nCreate and maintain business and technical requirements\\nIdentify technical solutions and perform feasibility analysis\\nCreate technical roadmaps for the operations Team\\nManage, identify and suggest processes for smoother program management to\\nensure a consistent and trouble free learning experience\\nCoordinate with IT and Admin to ensure smooth execution at various locations\\nTravel to other cities if required to manage residencies\\n\\nRelevant Background:\\nGraduate with an exceptional academic track record\\nCompetency: (Top 3)\\n1. Passion for learning and having great learning outcomes\\n2. Ability to multitask and coordinate with multiple stakeholders\\n3. Excellent knowledge in python, tableau and ML concepts\\n\\nRoleOther\\nIndustry TypeEducation, Teaching, Training\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\nTableauMachine LearningPython\\nProgram ManagementExploratory Data AnalysisUse CasesFeasibility AnalysisData CleansingData CollectionDashboardsSchedule Preparation\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\nRole Description:\\nA Sr. Data Scientist who lead the development of analytics / machine learning / AI models for generating future prediction using data.\\nResponsibilities : - Understanding the project requirement\\n- Understand if there is any already existing ML model\\n- Leading analytics project & provide necessary guidance to the team\\n- Understand the data & doing EDA\\n- Feature engineering - Building Data Science models\\n- Validate & Piloting ML models\\n- Model tuning & improvement\\nRequired Skills:\\n- Sound theoretical knowledge in ML algorithm and their application\\n- Strong fundamental on statistics\\n- Experience in leading multiple data science projects\\n- Hands on experience on Machine learning / data science\\n- Strong stakeholder management skills\\n- Expert in Python - Hand on experience in SPARK Scala or PySpark\\nAdded Advantage:\\n- Hands on experience in Azure data bricks\\n- Working experience in CPG domain\\nSkills Required:\\nDATA ANALYSIS, Machine learning, Python, Databricks\\nRoleTeam Lead/Technical Lead\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nAnalystdata sciencesparkMachine learningSCALAStakeholder managementStatisticsAnalyticsPython']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the detail job description\n",
    "\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"Not Available\")\n",
    "job_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Detailed Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Job description\\nData Scientist - Data Mining/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Atos Syntel Private Limited</td>\n",
       "      <td>Job description\\nWorking experience in Artific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Job description\\n\\nWe are hiring Data Scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Analyst-Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Job description\\nRole Description:\\nA Sr. Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "1  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "2    Data Scientist - Machine Learning (Commerce BU)   \n",
       "3                                     Data Scientist   \n",
       "4     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "5     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "6             Senior Data Scientist - NLP/ Python/ R   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8  Data Scientist and Senior Data Scientist Acade...   \n",
       "9                         Sr. Analyst-Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                          Bengaluru   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "4                                    Pune, Bengaluru   \n",
       "5                                    Pune, Bengaluru   \n",
       "6                               Bengaluru, Hyderabad   \n",
       "7  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "8                                          Bengaluru   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                        Company Name  \\\n",
       "0       Wrackle Technologies Pvt Ltd   \n",
       "1       Wrackle Technologies Pvt Ltd   \n",
       "2  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "3        Atos Syntel Private Limited   \n",
       "4                 Tech Mahindra Ltd.   \n",
       "5                 Tech Mahindra Ltd.   \n",
       "6                 AVI Consulting LLP   \n",
       "7                           CES Ltd.   \n",
       "8             RANDSTAD INDIA PVT LTD   \n",
       "9                   Mindtree Limited   \n",
       "\n",
       "                            Detailed Job Description  \n",
       "0  Job description\\nData Scientist - Data Mining/...  \n",
       "1  Job description\\nRoles and Responsibilities\\nR...  \n",
       "2                                      Not Available  \n",
       "3  Job description\\nWorking experience in Artific...  \n",
       "4                                      Not Available  \n",
       "5                                      Not Available  \n",
       "6  Job description\\nRoles and Responsibilities\\nS...  \n",
       "7  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "8  Job description\\n\\nWe are hiring Data Scientis...  \n",
       "9  Job description\\nRole Description:\\nA Sr. Data...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "\n",
    "data_scientist_jobs=pd.DataFrame({})\n",
    "data_scientist_jobs['Job Title']=job_title[0:10]    \n",
    "data_scientist_jobs['Job Location']=job_location[0:10]\n",
    "data_scientist_jobs['Company Name']=company_name[0:10]\n",
    "data_scientist_jobs['Detailed Job Description']=job_description[0:10]\n",
    "data_scientist_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: In this question you have to scrape data using the filters available on the webpage\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def jobs_data_Scientist(url):\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    ds_job_title=[]\n",
    "    ds_company_name=[]\n",
    "    ds_location=[]\n",
    "    ds_experience=[]\n",
    "    ds_salary=[]\n",
    "    \n",
    "    #Let's navigate to the search column\n",
    "    driver.find_element_by_xpath('//input[@class=\"sugInp\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//button[@class=\"btn\"]').click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Let's create filter for job location\n",
    "    driver.find_element_by_xpath('//span[@title=\"Delhi/NCR\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create filter for salary\n",
    "    driver.find_element_by_xpath('//span[@title=\"3-6 Lakhs\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's scrape the job tile\n",
    "    job_titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in job_titles:\n",
    "        ds_job_title.append(i.text)\n",
    "    \n",
    "    # Let's scrape the company name\n",
    "    company_name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for i in company_name:\n",
    "        ds_company_name.append(i.text)\n",
    "    \n",
    "    # Let's scrape the company location    \n",
    "    location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "    for i in location:\n",
    "        ds_location.append(i.text)\n",
    "    \n",
    "        \n",
    "    # Let's scrape the experience\n",
    "    experience=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')\n",
    "    for i in experience:\n",
    "        ds_experience.append(i.text)\n",
    "    \n",
    "    # Let's scrape the salary\n",
    "    salary=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "    for i in salary:\n",
    "        ds_salary.append(i.text)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    ds_jobs=pd.DataFrame({})\n",
    "    ds_jobs['Job Title']=ds_job_title[0:10]\n",
    "    ds_jobs['Company Name']=ds_company_name[0:10]\n",
    "    ds_jobs['Job Location']=ds_location[0:10]\n",
    "    ds_jobs['Experience']=ds_experience[0:10]\n",
    "    return ds_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - Computer Vision</td>\n",
       "      <td>IRIS SOFTWARE Inc</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ciena</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tech Mahindra hiring For Data Scientist- Noida</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Delhi NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2            Senior Data Scientist - Computer Vision   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4                                     Data Scientist   \n",
       "5  GCP Skilled Analytics Resources (Data engineer...   \n",
       "6                    Data Scientist Machine Learning   \n",
       "7     Tech Mahindra hiring For Data Scientist- Noida   \n",
       "8  Data Scientist - Commercial Planning and Analysis   \n",
       "9                  Business Analyst - Data Scientist   \n",
       "\n",
       "                         Company Name  \\\n",
       "0                      Country Veggie   \n",
       "1              IBM India Pvt. Limited   \n",
       "2                   IRIS SOFTWARE Inc   \n",
       "3           GABA Consultancy services   \n",
       "4                               Ciena   \n",
       "5  Aerial Telecom Solutions Pvt. Ltd.   \n",
       "6                           Delhivery   \n",
       "7                   tech mahindra ltd   \n",
       "8              Air Asia India Limited   \n",
       "9         HyreFox Consultants Pvt Ltd   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...   \n",
       "1                                   Gurgaon Gurugram   \n",
       "2                                          Delhi NCR   \n",
       "3                          Delhi NCR, Noida, Gurgaon   \n",
       "4                                   Gurgaon Gurugram   \n",
       "5                           Pune, Bengaluru, Gurgaon   \n",
       "6                                            Gurgaon   \n",
       "7                                              Noida   \n",
       "8                                 Delhi NCR, Gurgaon   \n",
       "9                                            Gurgaon   \n",
       "\n",
       "                                          Experience  \n",
       "0                                            1-3 Yrs  \n",
       "1                                      Not disclosed  \n",
       "2  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...  \n",
       "3                                            4-8 Yrs  \n",
       "4                                      Not disclosed  \n",
       "5                                   Gurgaon Gurugram  \n",
       "6                                            4-9 Yrs  \n",
       "7                                      Not disclosed  \n",
       "8                                          Delhi NCR  \n",
       "9                                            0-0 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "jobs_data_Scientist('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def glass_door_job(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    job_title=[]\n",
    "    company_name=[]\n",
    "    rating=[]\n",
    "    days=[]\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # If we visit the glassdoor page we will observe that, to navigate into the page we have to do the login\n",
    "    # Let's click on the sign-in butoon for logining\n",
    "    driver.find_element_by_xpath('//div[@class=\"locked-home-sign-in\"]').click()\n",
    "    \n",
    "    #Let's enter the demo login details\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('glassdoortestassignment@gmail.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('Assignment@1234')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's maximize the window size because there are some text font size is will has other element details in short window\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's fill the requied details in search column and click search\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida (India)')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's search the desired detail which we hve entered\n",
    "    driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    jobs=driver.find_elements_by_xpath('//article[@id=\"MainCol\"]/div/ul/li')\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        job.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Let's scrape the data\n",
    "        job_title.append((driver.find_element_by_xpath('//div[@class=\"css-1vg6q84 e1tk4kwz4\"]')).text)\n",
    "        company_name.append((driver.find_element_by_xpath('//div[@class=\"css-87uc0g e1tk4kwz1\"]')).text.replace('\\n',''))\n",
    "        try:\n",
    "            rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text)\n",
    "        except:\n",
    "            rating.append('NA')\n",
    "        try:\n",
    "            days.append((driver.find_element_by_xpath('//div[@data-test=\"job-age\"]')).text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    job_glass_door=pd.DataFrame({})\n",
    "    job_glass_door['Job Title']=job_title[0:10]\n",
    "    job_glass_door['Company Name']=company_name[0:10]\n",
    "    job_glass_door['Rating of the Company']=rating[0:10]\n",
    "    job_glass_door['Job Posted Days Ago']=days[0:10]\n",
    "    return job_glass_door       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Rating of the Company</th>\n",
       "      <th>Job Posted Days Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Emerging India Group1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>WishFin4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analytics Internship</td>\n",
       "      <td>Yellow Class5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Singh RanjayKumar(Proprietor Of Zee India Co)</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>dunnhumby4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Learning Engineer/ Data Scientist</td>\n",
       "      <td>Dürr Somac GmbH</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>xtLytics3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Kronos Incorporated4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job Title  \\\n",
       "0                             Data Scientist   \n",
       "1                             Data Scientist   \n",
       "2                             Data Scientist   \n",
       "3                             Data Scientist   \n",
       "4                  Data Analytics Internship   \n",
       "5                     Data Scientist/Analyst   \n",
       "6                     Applied Data Scientist   \n",
       "7  Machine Learning Engineer/ Data Scientist   \n",
       "8                         Jr. Data Scientist   \n",
       "9                   Principal Data Scientist   \n",
       "\n",
       "                                    Company Name Rating of the Company  \\\n",
       "0                              Biz2Credit Inc3.7                   3.7   \n",
       "1                                       Adobe3.5                   3.5   \n",
       "2                        Emerging India Group1.0                   1.0   \n",
       "3                                     WishFin4.0                   4.0   \n",
       "4                                Yellow Class5.0                   5.0   \n",
       "5  Singh RanjayKumar(Proprietor Of Zee India Co)                    NA   \n",
       "6                                   dunnhumby4.2                   4.2   \n",
       "7                                Dürr Somac GmbH                    NA   \n",
       "8                                    xtLytics3.0                   3.0   \n",
       "9                         Kronos Incorporated4.3                   4.3   \n",
       "\n",
       "  Job Posted Days Ago  \n",
       "0                30d+  \n",
       "1                30d+  \n",
       "2                30d+  \n",
       "3                30d+  \n",
       "4                30d+  \n",
       "5                30d+  \n",
       "6                30d+  \n",
       "7                30d+  \n",
       "8                30d+  \n",
       "9                30d+  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "glass_door_job('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def gd_salary(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    gd_min_salary=[]\n",
    "    gd_max_salary=[]\n",
    "    gd_avg_salary=[]\n",
    "    gd_company_name=[]\n",
    "    gd_rating=[]\n",
    "\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #Let's navigate to search bar and then type the Data Scientist job, location Noida and then click search button\n",
    "    driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys('Noida (India)')\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's search the element for required details\n",
    "    companies=driver.find_elements_by_xpath('//div[@data-test=\"job-info\"]/p[2]')\n",
    "    avg_salary=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong')\n",
    "    min_salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container \"]/span[1]')\n",
    "    max_salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container \"]/span[2]')\n",
    "    rating='NA'\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    for i in companies:\n",
    "        gd_company_name.append(i.text)\n",
    "    for i in avg_salary:\n",
    "        gd_avg_salary.append(i.text)\n",
    "    for i in min_salary:\n",
    "        gd_min_salary.append(i.text)\n",
    "    for i in max_salary:\n",
    "        gd_max_salary.append(i.text)\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    salaries=pd.DataFrame({})\n",
    "    salaries['Company Name']=gd_company_name[:10]\n",
    "    salaries['Avgerage Salary']=gd_avg_salary[:10]\n",
    "    salaries['Minimum Salary']=gd_min_salary[:10]\n",
    "    salaries['Maximum Salary']=gd_max_salary[:10]\n",
    "    salaries['Rating of the Company']=rating[:10]\n",
    "    return salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Avgerage Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Rating of the Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,64,182</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,630K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,30,968</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,614K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 5,99,668</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,010K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 9,94,055</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,215K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,39,040</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹2,732K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,37,114</td>\n",
       "      <td>₹717K</td>\n",
       "      <td>₹1,575K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,80,374</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,152K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹ 11,98,792</td>\n",
       "      <td>₹621K</td>\n",
       "      <td>₹1,696K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹ 10,08,143</td>\n",
       "      <td>₹793K</td>\n",
       "      <td>₹1,264K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,34,989</td>\n",
       "      <td>₹576K</td>\n",
       "      <td>₹1,500K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Name Avgerage Salary Minimum Salary  \\\n",
       "0                       Delhivery     ₹ 12,64,182          ₹450K   \n",
       "1              Ericsson-Worldwide      ₹ 7,30,968          ₹350K   \n",
       "2       Tata Consultancy Services      ₹ 5,99,668          ₹336K   \n",
       "3                       Accenture      ₹ 9,94,055          ₹577K   \n",
       "4                             IBM      ₹ 7,39,040          ₹587K   \n",
       "5              UnitedHealth Group     ₹ 13,37,114          ₹717K   \n",
       "6              Valiance Solutions      ₹ 7,80,374          ₹502K   \n",
       "7                      Innovaccer     ₹ 11,98,792          ₹621K   \n",
       "8  Cognizant Technology Solutions     ₹ 10,08,143          ₹793K   \n",
       "9                     EXL Service     ₹ 11,34,989          ₹576K   \n",
       "\n",
       "  Maximum Salary Rating of the Company  \n",
       "0       ₹11,630K                    NA  \n",
       "1        ₹1,614K                    NA  \n",
       "2        ₹1,010K                    NA  \n",
       "3        ₹2,215K                    NA  \n",
       "4        ₹2,732K                    NA  \n",
       "5        ₹1,575K                    NA  \n",
       "6        ₹1,152K                    NA  \n",
       "7        ₹1,696K                    NA  \n",
       "8        ₹1,264K                    NA  \n",
       "9        ₹1,500K                    NA  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "gd_salary('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def flipkart_sunglasses(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sunglasses product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sunglass_brand_name=[]\n",
    "    sunglass_description=[]\n",
    "    sunglass_price=[]\n",
    "    sunglass_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sunglass_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sunglass_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sunglass_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sunglass_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sunglasses_flip=pd.DataFrame({})\n",
    "    sunglasses_flip['Product Brand']=sunglass_brand_name[:100]\n",
    "    sunglasses_flip['Product Description']=sunglass_description[:100]\n",
    "    sunglasses_flip['Price of Product']=sunglass_price[:100]\n",
    "    sunglasses_flip['Discount on Product']=sunglass_discount[:100]\n",
    "    return sunglasses_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price of Product</th>\n",
       "      <th>Discount on Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polaroid</td>\n",
       "      <td>Polarized Rectangular Sunglasses (54)</td>\n",
       "      <td>₹2,520</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (49)</td>\n",
       "      <td>₹629</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (59)</td>\n",
       "      <td>₹909</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>Polarized Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,176</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Gansta</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored, Night Vision, Riding ...</td>\n",
       "      <td>₹327</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection Wayfarer, Round Sunglasses (63)</td>\n",
       "      <td>₹627</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product Brand                                Product Description  \\\n",
       "0       Polaroid              Polarized Rectangular Sunglasses (54)   \n",
       "1      Royal Son         UV Protection Retro Square Sunglasses (49)   \n",
       "2       Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "3       Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "4       Fastrack             UV Protection Wayfarer Sunglasses (56)   \n",
       "..           ...                                                ...   \n",
       "95      Fastrack          UV Protection Rectangular Sunglasses (59)   \n",
       "96          IDEE                  Polarized Aviator Sunglasses (58)   \n",
       "97        Gansta   UV Protection, Mirrored Wayfarer Sunglasses (53)   \n",
       "98         NuVew  UV Protection, Mirrored, Night Vision, Riding ...   \n",
       "99        Aislin      UV Protection Wayfarer, Round Sunglasses (63)   \n",
       "\n",
       "   Price of Product Discount on Product  \n",
       "0            ₹2,520             30% off  \n",
       "1              ₹629             68% off  \n",
       "2              ₹499             37% off  \n",
       "3              ₹499             37% off  \n",
       "4              ₹599             33% off  \n",
       "..              ...                 ...  \n",
       "95             ₹909             30% off  \n",
       "96           ₹1,176             60% off  \n",
       "97             ₹199             80% off  \n",
       "98             ₹327             64% off  \n",
       "99             ₹627             80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "flipkart_sunglasses('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def iphone_100_review(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "        \n",
    "        reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in reviews:\n",
    "            review_summary.append(i.text)\n",
    "        \n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        time.sleep(10)    \n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(10)\n",
    "        j+=1\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    iphone_review=pd.DataFrame({})\n",
    "    iphone_review['Rating']=rating\n",
    "    iphone_review['Review Summary']=review_summary\n",
    "    iphone_review['Full Reviews']=full_review\n",
    "    return iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Well you all know the specifications . One of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5  Highly recommended   \n",
       "3       5    Perfect product!   \n",
       "4       5           Brilliant   \n",
       "..    ...                 ...   \n",
       "95      5           Brilliant   \n",
       "96      5   Worth every penny   \n",
       "97      5           Wonderful   \n",
       "98      5       Great product   \n",
       "99      5  Highly recommended   \n",
       "\n",
       "                                         Full Reviews  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "..                                                ...  \n",
       "95  I have migrated from OP 7pro... and trust me, ...  \n",
       "96  Previously I was using one plus 3t it was a gr...  \n",
       "97  This is my first ever I phone. Before this I w...  \n",
       "98  Well you all know the specifications . One of ...  \n",
       "99  It's my first time to use iOS phone and I am l...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "iphone_100_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def flip_sneakers(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sneaker product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sneaker_brand_name=[]\n",
    "    sneaker_description=[]\n",
    "    sneaker_price=[]\n",
    "    sneaker_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sneaker_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sneaker_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sneaker_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sneaker_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sneakers_flipkart=pd.DataFrame({})\n",
    "    sneakers_flipkart['Brand Name']=sneaker_brand_name[:100]\n",
    "    sneakers_flipkart['Product Descriptions']=sneaker_description[:100]\n",
    "    sneakers_flipkart['Price']=sneaker_price[:100]\n",
    "    sneakers_flipkart['Discount %']=sneaker_discount[:100]\n",
    "    return sneakers_flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earton</td>\n",
       "      <td>Casual Sneakers Shoes for Men Pack of 5 Combo(...</td>\n",
       "      <td>₹759</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super 445 Fashion Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Lovehush</td>\n",
       "      <td>Men's Denim Casual Sneakers Jeans Shoes Sneake...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ducati</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,299</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>LOOK TWICE</td>\n",
       "      <td>LOOK TWICE Men's Casual Canvas Sport Shoes, Bo...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand Name                               Product Descriptions  \\\n",
       "0                Earton  Casual Sneakers Shoes for Men Pack of 5 Combo(...   \n",
       "1             Rockfield                                   Sneakers For Men   \n",
       "2                Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3   World Wear Footwear  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "4          Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95               Chevit                 Super 445 Fashion Sneakers For Men   \n",
       "96             Lovehush  Men's Denim Casual Sneakers Jeans Shoes Sneake...   \n",
       "97                   TR                                   Sneakers For Men   \n",
       "98               Ducati                                   Sneakers For Men   \n",
       "99           LOOK TWICE  LOOK TWICE Men's Casual Canvas Sport Shoes, Bo...   \n",
       "\n",
       "     Price Discount %  \n",
       "0     ₹759    69% off  \n",
       "1     ₹399    60% off  \n",
       "2     ₹474    76% off  \n",
       "3     ₹474    76% off  \n",
       "4     ₹379    62% off  \n",
       "..     ...        ...  \n",
       "95    ₹389    62% off  \n",
       "96    ₹379    70% off  \n",
       "97    ₹599    64% off  \n",
       "98  ₹1,299    62% off  \n",
       "99    ₹379    55% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "flip_sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Go to the link -\n",
    "https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def shoes_myntra(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r'chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    brand_name=[]\n",
    "    description=[]\n",
    "    product_price=[]\n",
    "    \n",
    "    #Let's apply filter for price\n",
    "    driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's apply filter for colour\n",
    "    driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<2:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        brands=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "        for q in brands:\n",
    "            brand_name.append(q.text)\n",
    "        \n",
    "        descs=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "        for q in descs:\n",
    "            description.append(q.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "        for q in prices:\n",
    "            product_price.append(q.text)\n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()    \n",
    "        time.sleep(5)\n",
    "        j+=1\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    myntra_shoes=pd.DataFrame({})\n",
    "    myntra_shoes['Brand of the Shoes']=brand_name[0:100]\n",
    "    myntra_shoes['Short Shoes Description']=description[0:100]\n",
    "    myntra_shoes['Price of the Shoes']=product_price[0:100]\n",
    "    return myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoes Description</th>\n",
       "      <th>Price of the Shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men HYBRID NETFIT Running Shoe</td>\n",
       "      <td>Rs. 6599Rs. 10999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Superstar Sneakers</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men SOLAR DRIVE 19 M Running</td>\n",
       "      <td>Rs. 8639Rs. 11999(28% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>Rs. 7996Rs. 9995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Nite Jogger Fluid Sneakers</td>\n",
       "      <td>Rs. 9749Rs. 12999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>Rs. 5399Rs. 8999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>SPEED Orbiter Running Shoes</td>\n",
       "      <td>Rs. 9749Rs. 12999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breathe TR 2</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Brogues</td>\n",
       "      <td>Rs. 6293Rs. 8990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VERONA Sneakers</td>\n",
       "      <td>Rs. 7996Rs. 9995(20% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand of the Shoes           Short Shoes Description  \\\n",
       "0                Puma    Men HYBRID NETFIT Running Shoe   \n",
       "1    ADIDAS Originals            Men Superstar Sneakers   \n",
       "2              ADIDAS      Men SOLAR DRIVE 19 M Running   \n",
       "3                Nike     PEGASUS FLYEASE Running Shoes   \n",
       "4    ADIDAS Originals    Men Nite Jogger Fluid Sneakers   \n",
       "..                ...                               ...   \n",
       "95               ALDO                     Women Sandals   \n",
       "96               Puma       SPEED Orbiter Running Shoes   \n",
       "97       UNDER ARMOUR        Women Charged Breathe TR 2   \n",
       "98       Kenneth Cole  Men Solid Leather Formal Brogues   \n",
       "99               Nike     Women AIR MAX VERONA Sneakers   \n",
       "\n",
       "            Price of the Shoes  \n",
       "0   Rs. 6599Rs. 10999(40% OFF)  \n",
       "1   Rs. 7699Rs. 10999(30% OFF)  \n",
       "2   Rs. 8639Rs. 11999(28% OFF)  \n",
       "3    Rs. 7996Rs. 9995(20% OFF)  \n",
       "4   Rs. 9749Rs. 12999(25% OFF)  \n",
       "..                         ...  \n",
       "95   Rs. 5399Rs. 8999(40% OFF)  \n",
       "96  Rs. 9749Rs. 12999(25% OFF)  \n",
       "97                    Rs. 7999  \n",
       "98   Rs. 6293Rs. 8990(30% OFF)  \n",
       "99   Rs. 7996Rs. 9995(20% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "shoes=shoes_myntra('https://www.myntra.com/shoes')\n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can observe from the above table that the price and discounted price of the shoes are tagged under same element id. So we have to split the price and discounted price.\n",
    "##### And create a dataframe with the current price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shoes_myntra=shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's spit the price and the discounted price\n",
    "\n",
    "new_price=shoes_myntra['Price of the Shoes'].str.split(\"Rs.\",n=2,expand=True)\n",
    "shoes_myntra['Price in Rs']=new_price[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's drop the old price column\n",
    "\n",
    "shoes_myntra.drop(columns=('Price of the Shoes'),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoes Description</th>\n",
       "      <th>Price in Rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men HYBRID NETFIT Running Shoe</td>\n",
       "      <td>6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Superstar Sneakers</td>\n",
       "      <td>7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men SOLAR DRIVE 19 M Running</td>\n",
       "      <td>8639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Nite Jogger Fluid Sneakers</td>\n",
       "      <td>9749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>SPEED Orbiter Running Shoes</td>\n",
       "      <td>9749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breathe TR 2</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Brogues</td>\n",
       "      <td>6293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VERONA Sneakers</td>\n",
       "      <td>7996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand of the Shoes           Short Shoes Description Price in Rs\n",
       "0                Puma    Men HYBRID NETFIT Running Shoe        6599\n",
       "1    ADIDAS Originals            Men Superstar Sneakers        7699\n",
       "2              ADIDAS      Men SOLAR DRIVE 19 M Running        8639\n",
       "3                Nike     PEGASUS FLYEASE Running Shoes        7996\n",
       "4    ADIDAS Originals    Men Nite Jogger Fluid Sneakers        9749\n",
       "..                ...                               ...         ...\n",
       "95               ALDO                     Women Sandals        5399\n",
       "96               Puma       SPEED Orbiter Running Shoes        9749\n",
       "97       UNDER ARMOUR        Women Charged Breathe TR 2        7999\n",
       "98       Kenneth Cole  Men Solid Leather Formal Brogues        6293\n",
       "99               Nike     Women AIR MAX VERONA Sneakers        7996\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_myntra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def laptop(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    item_title=[]\n",
    "    price=[]\n",
    "    rating=[]\n",
    "    \n",
    "    #Let's search for laptop product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "    driver.find_element_by_xpath('//input[@type=\"submit\"]').click()\n",
    "        \n",
    "    #Let's apply filter for \"Intel Core i7\"\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a',).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's apply filter for \"Intel Core i9\"  \n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()\n",
    "        \n",
    "    # Let's scrape the data\n",
    "    titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for i in titles:\n",
    "        item_title.append(i.text)\n",
    "    prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "    for i in ratings:\n",
    "        rating.append(i.get_attribute('aria-label'))\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    amazon_laptops=pd.DataFrame({})\n",
    "    amazon_laptops['Title']=item_title[:10]\n",
    "    amazon_laptops['Price']=price[:10]\n",
    "    amazon_laptops['Rating']=rating[:10]\n",
    "    return amazon_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>77,990</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>50,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>1,97,200</td>\n",
       "      <td>2.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>50,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>2,68,325</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI GF65 Thin Core i7 9th Gen - (16 GB/512 GB ...</td>\n",
       "      <td>74,990</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td>75,493</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>85,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td>95,290</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price  \\\n",
       "0  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    77,990   \n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i5-1...    50,999   \n",
       "2  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  1,97,200   \n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...    50,999   \n",
       "4  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  2,68,325   \n",
       "5  MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...    89,990   \n",
       "6  MSI GF65 Thin Core i7 9th Gen - (16 GB/512 GB ...    74,990   \n",
       "7  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...    75,493   \n",
       "8  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...    85,990   \n",
       "9  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...    95,290   \n",
       "\n",
       "               Rating  \n",
       "0  3.6 out of 5 stars  \n",
       "1  4.2 out of 5 stars  \n",
       "2  2.4 out of 5 stars  \n",
       "3  4.2 out of 5 stars  \n",
       "4  5.0 out of 5 stars  \n",
       "5  4.2 out of 5 stars  \n",
       "6  3.5 out of 5 stars  \n",
       "7  4.0 out of 5 stars  \n",
       "8  4.1 out of 5 stars  \n",
       "9  4.3 out of 5 stars  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "laptop('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# THANK YOU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
